diff --git a/mani_skill/agents/base_agent.py b/mani_skill/agents/base_agent.py
index adb4c6c..ee154bf 100644
--- a/mani_skill/agents/base_agent.py
+++ b/mani_skill/agents/base_agent.py
@@ -87,30 +87,36 @@ class BaseAgent:
         agent_idx: Optional[str] = None,
         initial_pose: Optional[Union[sapien.Pose, Pose]] = None,
     ):
+        print("-----------------------------------BaseAgent---__init__---1")
         self.scene = scene
         self._control_freq = control_freq
         self._agent_idx = agent_idx
-
+        print("-----------------------------------BaseAgent---__init__---2")
         self.robot: Articulation = None
         """The robot object, which is an Articulation. Data like pose, qpos etc. can be accessed from this object."""
         self.controllers: Dict[str, BaseController] = dict()
         """The controllers of the robot."""
         self.sensors: Dict[str, BaseSensor] = dict()
         """The sensors that come with the robot."""
-
+        print("-----------------------------------BaseAgent---__init__---3")
         self._load_articulation(initial_pose)
+        print("-----------------------------------BaseAgent---__init__---4")
         self._after_loading_articulation()
+        print("-----------------------------------BaseAgent---__init__---5")
 
         # Controller
         self.supported_control_modes = list(self._controller_configs.keys())
         """List of all possible control modes for this robot."""
         if control_mode is None:
             control_mode = self.supported_control_modes[0]
+        print("-----------------------------------BaseAgent---__init__---6")
         # The control mode after reset for consistency
         self._default_control_mode = control_mode
         self.set_control_mode()
+        print("-----------------------------------BaseAgent---__init__---7")
 
         self._after_init()
+        print("-----------------------------------BaseAgent---__init__---8")
 
     @property
     def _sensor_configs(self) -> List[BaseSensorConfig]:
diff --git a/mani_skill/envs/sapien_env.py b/mani_skill/envs/sapien_env.py
index 0845901..4d1dfb7 100644
--- a/mani_skill/envs/sapien_env.py
+++ b/mani_skill/envs/sapien_env.py
@@ -198,7 +198,8 @@ class BaseEnv(gym.Env):
         sim_config: Union[SimConfig, dict] = dict(),
         reconfiguration_freq: Optional[int] = None,
         sim_backend: str = "auto",
-        render_backend: str = "gpu",
+        # render_backend: str = "gpu",
+        render_backend: str = "cpu",
         parallel_in_single_scene: bool = False,
         enhanced_determinism: bool = False,
     ):
diff --git a/mani_skill/envs/tasks/digital_twins/base_env.py b/mani_skill/envs/tasks/digital_twins/base_env.py
index 83ca075..e43265d 100644
--- a/mani_skill/envs/tasks/digital_twins/base_env.py
+++ b/mani_skill/envs/tasks/digital_twins/base_env.py
@@ -1,7 +1,8 @@
 import os
 from typing import Dict, List
 
-import cv2
+# todo xiao
+# import cv2
 import gymnasium as gym
 import numpy as np
 import sapien.physx as physx
@@ -47,9 +48,10 @@ class BaseDigitalTwinEnv(BaseEnv):
                         "If you installed this repo through 'pip install .' , "
                         "you can download this directory https://github.com/simpler-env/ManiSkill2_real2sim/tree/main/data to get the real-world image overlay assets. "
                     )
-                self._rgb_overlay_images[camera_name] = cv2.cvtColor(
-                    cv2.imread(path), cv2.COLOR_BGR2RGB
-                )  # (H, W, 3); float32
+                # todo xiao
+                # self._rgb_overlay_images[camera_name] = cv2.cvtColor(
+                #     cv2.imread(path), cv2.COLOR_BGR2RGB
+                # )  # (H, W, 3); float32
         else:
             self._rgb_overlay_images = None
 
@@ -93,15 +95,16 @@ class BaseDigitalTwinEnv(BaseEnv):
 
         for camera_name in self.rgb_overlay_paths.keys():
             sensor = self._sensor_configs[camera_name]
-            if isinstance(sensor, CameraConfig):
-                if isinstance(self._rgb_overlay_images[camera_name], torch.Tensor):
-                    continue
-                rgb_overlay_img = cv2.resize(
-                    self._rgb_overlay_images[camera_name], (sensor.width, sensor.height)
-                )
-                self._rgb_overlay_images[camera_name] = common.to_tensor(
-                    rgb_overlay_img, device=self.device
-                )
+            # todo xiao
+            # if isinstance(sensor, CameraConfig):
+            #     if isinstance(self._rgb_overlay_images[camera_name], torch.Tensor):
+            #         continue
+            #     rgb_overlay_img = cv2.resize(
+            #         self._rgb_overlay_images[camera_name], (sensor.width, sensor.height)
+            #     )
+            #     self._rgb_overlay_images[camera_name] = common.to_tensor(
+            #         rgb_overlay_img, device=self.device
+            #     )
 
     def _green_sceen_rgb(self, rgb, segmentation, overlay_img):
         """returns green screened RGB data given a batch of RGB and segmentation images and one overlay image"""
@@ -139,22 +142,23 @@ class BaseDigitalTwinEnv(BaseEnv):
     def get_obs(self, info: dict = None):
         obs = super().get_obs(info)
 
-        # "greenscreen" process
-        if (
-            self.obs_mode_struct.visual.rgb
-            and self.obs_mode_struct.visual.segmentation
-            and self.rgb_overlay_paths is not None
-        ):
-            # get the actor ids of objects to manipulate; note that objects here are not articulated
-            for camera_name in self._rgb_overlay_images.keys():
-                # obtain overlay mask based on segmentation info
-                assert (
-                    "segmentation" in obs["sensor_data"][camera_name].keys()
-                ), "Image overlay requires segment info in the observation!"
-                green_screened_rgb = self._green_sceen_rgb(
-                    obs["sensor_data"][camera_name]["rgb"],
-                    obs["sensor_data"][camera_name]["segmentation"],
-                    self._rgb_overlay_images[camera_name],
-                )
-                obs["sensor_data"][camera_name]["rgb"] = green_screened_rgb
+        # todo xiao
+        # # "greenscreen" process
+        # if (
+        #     self.obs_mode_struct.visual.rgb
+        #     and self.obs_mode_struct.visual.segmentation
+        #     and self.rgb_overlay_paths is not None
+        # ):
+        #     # get the actor ids of objects to manipulate; note that objects here are not articulated
+        #     for camera_name in self._rgb_overlay_images.keys():
+        #         # obtain overlay mask based on segmentation info
+        #         assert (
+        #             "segmentation" in obs["sensor_data"][camera_name].keys()
+        #         ), "Image overlay requires segment info in the observation!"
+        #         green_screened_rgb = self._green_sceen_rgb(
+        #             obs["sensor_data"][camera_name]["rgb"],
+        #             obs["sensor_data"][camera_name]["segmentation"],
+        #             self._rgb_overlay_images[camera_name],
+        #         )
+        #         obs["sensor_data"][camera_name]["rgb"] = green_screened_rgb
         return obs
diff --git a/mani_skill/examples/demo_robot.py b/mani_skill/examples/demo_robot.py
index 54fb6e2..c00fea5 100644
--- a/mani_skill/examples/demo_robot.py
+++ b/mani_skill/examples/demo_robot.py
@@ -45,6 +45,7 @@ def main():
         render_mode="human",
         sim_config=dict(sim_freq=args.sim_freq, control_freq=args.control_freq),
         sim_backend=args.sim_backend,
+        seed=args.seed,
     )
     env.reset(seed=0)
     env: BaseEnv = env.unwrapped
diff --git a/mani_skill/utils/building/urdf_loader.py b/mani_skill/utils/building/urdf_loader.py
index cd7be75..239dd53 100644
--- a/mani_skill/utils/building/urdf_loader.py
+++ b/mani_skill/utils/building/urdf_loader.py
@@ -25,7 +25,9 @@ class URDFLoader(SapienURDFLoader):
     name: str = None
     disable_self_collisions: bool = False
 
-    def parse(self, urdf_file, srdf_file=None, package_dir=None) -> ParsedURDFData:
+    # todo xiao
+    # def parse(self, urdf_file, srdf_file=None, package_dir=None) -> ParsedURDFData:
+    def parse(self, urdf_file, srdf_file=None, package_dir=None):
         articulation_builders, actor_builders, cameras = super().parse(
             urdf_file, srdf_file, package_dir
         )
@@ -40,11 +42,20 @@ class URDFLoader(SapienURDFLoader):
                     l.collision_groups[2] |= 1 << 29
         for i, b in enumerate(actor_builders):
             b.set_name(f"{self.name}-actor-{i}")
-        return dict(
+        
+        # todo xiao
+        # return ParsedURDFData(
+        #     articulation_builders=articulation_builders,
+        #     actor_builders=actor_builders,
+        #     cameras=cameras,
+        # )
+        udata = ParsedURDFData(
             articulation_builders=articulation_builders,
             actor_builders=actor_builders,
             cameras=cameras,
         )
+        print(f"---------------------------------urdf_loader---parse---udata = {udata}")
+        return articulation_builders, actor_builders, cameras, udata
 
     def load_file_as_articulation_builder(
         self, urdf_file, srdf_file=None, package_dir=None
@@ -73,10 +84,19 @@ class URDFLoader(SapienURDFLoader):
         """
         if name is not None:
             self.name = name
-        _parsed_urdf_data = self.parse(urdf_file, srdf_file, package_dir)
-        articulation_builders = _parsed_urdf_data["articulation_builders"]
-        actor_builders = _parsed_urdf_data["actor_builders"]
-        cameras = _parsed_urdf_data["cameras"]
+        # todo xiao
+        # _parsed_urdf_data = self.parse(urdf_file, srdf_file, package_dir)
+        # articulation_builders = _parsed_urdf_data["articulation_builders"]
+        # actor_builders = _parsed_urdf_data["actor_builders"]
+        # cameras = _parsed_urdf_data["cameras"]
+        articulation_builders, actor_builders, cameras, udata = self.parse(urdf_file, srdf_file, package_dir)
+        print(f"---------------------------------urdf_loader---load---udata = {udata}")
+        _articulation_builders = udata['articulation_builders']
+        _actor_builders = udata['actor_builders']
+        _cameras = udata['cameras']
+        print(f"---------------------------------urdf_loader---load---_articulation_builders = {_articulation_builders}, len(_articulation_builders) = {len(_articulation_builders)}")
+        print(f"---------------------------------urdf_loader---load---_actor_builders = {_actor_builders}, len(_actor_builders) = {len(_actor_builders)}")
+        print(f"---------------------------------urdf_loader---load---_cameras = {_cameras}, len(_cameras) = {len(_cameras)}")
 
         if len(articulation_builders) > 1 or len(actor_builders) != 0:
             raise Exception(
diff --git a/setup.py b/setup.py
index 43701e2..7fd8f7f 100644
--- a/setup.py
+++ b/setup.py
@@ -24,12 +24,13 @@ setup(
     python_requires=">=3.9",
     setup_requires=["setuptools>=62.3.0"],
     install_requires=[
-        "numpy>=1.22,<2.0.0",
+        # "numpy>=1.22,<2.0.0",
+        "numpy==1.23.3",
         "scipy",
         "dacite",
-        "gymnasium==0.29.1",
-        "sapien==3.0.0.b1",
-        "h5py",
+        "gymnasium",
+        # # "sapien==3.0.0.b1",
+        # "h5py",
         "pyyaml",
         "tqdm",
         "GitPython",
@@ -37,13 +38,13 @@ setup(
         "transforms3d",
         "trimesh",
         "imageio",
-        "imageio[ffmpeg]",
-        "mplib==0.1.1;platform_system=='Linux'",
-        "fast_kinematics==0.2.2;platform_system=='Linux'",
+        # "imageio[ffmpeg]",
+        # "mplib==0.1.1;platform_system=='Linux'",
+        # "fast_kinematics==0.2.2;platform_system=='Linux'",
         "IPython",
-        "pytorch_kinematics==0.7.4",
+        # "pytorch_kinematics==0.7.4",
         "pynvml",  # gpu monitoring
-        "tyro>=0.8.5",  # nice, typed, command line arg parser
+        "tyro",  # nice, typed, command line arg parser
         "huggingface_hub",  # we use HF to version control some assets/datasets more easily
     ],
     # Glob patterns do not automatically match dotfiles
